"""
This script calculates the ratio of the number of statements in the INDRA
Database for a gene to the number of citations in Entrez Gene for that gene.
It depends on two pre-computed files--entrez_all_pmids.json, which can be
generated by running get_pmids.py in the `hgnc_all` subdirectory of the INDRA
Apps repository. It also depends on a dump of the INDRA Database as a Pandas
dataframe, which can be generated by running the `dump_sif.py` script in
`indra_db.util`.
"""

import os
import time
import json
import random
import pickle
import numpy as np
from matplotlib import pyplot as plt
from indra.util import read_unicode_csv
from indra.databases import hgnc_client
from indra_db.util import get_primary_db

def get_hgnc_entries():
    """Get approved HGNC entries as a list of (name, id) pairs."""
    # Get all HGNC IDs
    hgnc_file = '../../indra/indra/resources/hgnc_entries.tsv'
    lines = read_unicode_csv(hgnc_file, delimiter='\t')
    # Skip the header line
    next(lines)
    hgnc_entries = [(line[1], line[0].split(':')[1])
                    for line in lines if line[3] == 'Approved']
    return hgnc_entries


def get_stmt_count_from_db():
    """Not recommended, very slow."""
    hgnc_entries = get_hgnc_entries()
    random.seed(1)
    random.shuffle(hgnc_entries)

    db = get_primary_db()
    CHECKPOINT_FILE = 'checkpoint.pkl'

    if os.path.exists(CHECKPOINT_FILE):
        print("Loading from checkpoint")
        with open(CHECKPOINT_FILE, 'rb') as f:
            start_ix, stmt_counts = pickle.load(f)
        if start_ix == len(hgnc_entries):
            return stmt_counts
    else:
        start_ix = 0
        stmt_counts = {}

    start = time.time()
    CHECKPOINT_INTERVAL = 100
    for ix in range(start_ix, len(hgnc_entries)):
        hgnc_name, hgnc_id = hgnc_entries[ix]
        # Save the state of the dict
        if ix != 0 and ix % CHECKPOINT_INTERVAL == 0:
            print("Saving checkpoint")
            with open(CHECKPOINT_FILE, 'wb') as f:
                pickle.dump((ix, stmt_counts), f)
        # Run the query
        q = db.filter_query(db.RawStatements,
                db.RawAgents.stmt_id == db.RawStatements.id,
                 db.RawAgents.db_name.like('HGNC'),
                 db.RawAgents.db_id.like(str(hgnc_id)))
        # Get the statement count
        stmt_count = q.count()
        # Print some stats
        elapsed = time.time() - start
        time_per_gene = elapsed / (ix - start_ix + 1)
        num_remaining = len(hgnc_entries) - (ix + 1)
        sec_remaining = time_per_gene * num_remaining
        min_remaining = sec_remaining / 60.
        print("%d of %d: %d statements for %s (%s): Est %.2f min remaining" %
                    (ix+1, len(hgnc_entries), stmt_count, hgnc_name, hgnc_id,
                     min_remaining))
        # Put count into dict
        stmt_counts[hgnc_name] = stmt_count
    # Save final results
    with open(CHECKPOINT_FILE, 'wb') as f:
        pickle.dump(len(hgnc_entries), stmt_counts)

    return stmt_counts


def get_stmt_count_from_stmt_df(df_filename):
    with open(, 'rb') as f:
        df = pickle.load(f)
    df_A = df[df['agA_ns'] == 'HGNC'].groupby('agA_id').agg(
            {'evidence_count': 'sum'})
    df_B = df[df['agB_ns'] == 'HGNC'].groupby('agB_id').agg(
                                        {'evidence_count': 'sum'})
    df_AB = df[(df['agA_ns'] == 'HGNC') &
               (df['agB_ns'] == 'HGNC') &
               (df['agA_id'] == df['agB_id'])].groupby('agA_id').agg(
                                        {'evidence_count': 'sum'})
    # Combine the counts
    df_join = df_A.join(df_B, lsuffix='A', rsuffix='B').join(df_AB)
    df_join = df_join.fillna(value=0)
    stmt_counts = (df_join['evidence_countA'] +
                   df_join['evidence_countB'] -
                   df_join['evidence_count'])

    return stmt_counts


if __name__ == '__main__':
    # Get statement counts from INDRA DB dump
    df_filename = 'stmt_df.pkl'
    stmt_count_df = get_stmt_count_from_stmt_df(df_filename)

    # Get citation counts from Entrez
    with open('entrez_all_pmids.json', 'rt') as f:
        entrez = json.load(f)

    # Put together paired list of counts by gene
    stmt_counts = []
    citations = []
    counter = 0
    log_diffs_by_gene = {}
    for hgnc_id, stmt_count in stmt_count_df.iteritems():
        print(counter)
        if counter > 100:
            pass #break
        counter += 1
        hgnc_name = hgnc_client.get_hgnc_name(hgnc_id)
        assert hgnc_name is not None
        try:
            citation_count = len(entrez[hgnc_name])
            citations.append(citation_count)
            stmt_counts.append(stmt_count)
            if stmt_counts != 0 and citation_count != 0:
                log_diffs_by_gene[hgnc_name] = (np.log10(stmt_count) -
                                                np.log10(citation_count))
        # Will trigger KeyError if the gene name has changed since the
        # PMIDs were obtained from Entrez; skip these
        except KeyError:
            pass

    # Differences, sorted by magnitude
    sorted_diffs = sorted([(k, v) for k, v in log_diffs_by_gene.items()],
                          key=lambda x: x[1], reverse=True)

    plt.ion()
    # Scatterplot
    plt.figure()
    plt.plot(citations, stmt_counts, marker='.', linestyle='')
    plt.xlabel('Citations in Entrez')
    plt.ylabel('No. of Statements')
    plt.xscale('log')
    plt.yscale('log')

    # Log differences
    plt.figure()
    plt.hist(log_diffs_by_gene.values(), bins=100)
    plt.ylabel('No. of genes')
    plt.xlabel('log10(stmts) - log10(citations)')
